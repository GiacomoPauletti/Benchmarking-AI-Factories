Bootstrap: docker
From: nvidia/cuda:11.6.1-devel-ubuntu20.04

%environment
    export PYTHONPATH=/app:$PYTHONPATH
    export CUDA_VISIBLE_DEVICES=0

%post
    # Fix apt permissions for rootless builds
    export DEBIAN_FRONTEND=noninteractive
    
    # Install system dependencies
    apt-get update && apt-get install -y \
        python3 \
        python3-pip \
        python3-dev \
        git \
        wget \
        curl \
        build-essential \
        && rm -rf /var/lib/apt/lists/*

    # Install Python dependencies for vLLM
    python3 -m pip install --upgrade pip
    python3 -m pip install \
        vllm \
        fastapi \
        uvicorn \
        torch \
        transformers \
        accelerate

    # Create app directory
    mkdir -p /app

%files
    # Copy any required model files or configs here

%runscript
    echo "Starting vLLM server..."
    python3 -m vllm.entrypoints.openai.api_server \
        --model microsoft/DialoGPT-medium \
        --host 0.0.0.0 \
        --port 8000 \
        --tensor-parallel-size 1