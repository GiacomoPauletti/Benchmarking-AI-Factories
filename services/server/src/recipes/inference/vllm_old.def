
Bootstrap: docker
From: python:3.10-slim

%environment
    export PYTHONPATH=/app:$PYTHONPATH
    export CUDA_VISIBLE_DEVICES=0

%post
    # Install Python dependencies for vLLM
    pip install --upgrade pip
    pip install \
        vllm \
        fastapi \
        uvicorn \
        torch \
        transformers \
        accelerate
    # Create app directory
    mkdir -p /app

%files
    # Copy any required model files or configs here

%runscript
    echo "Starting vLLM server..."
    python -m vllm.entrypoints.openai.api_server \
        --model microsoft/DialoGPT-medium \
        --host 0.0.0.0 \
        --port 8000 \
        --tensor-parallel-size 1