{"openapi":"3.1.0","info":{"title":"AI Factory Server Service","description":"SLURM + Apptainer orchestration for AI workloads","version":"1.0.0"},"paths":{"/":{"get":{"summary":"Root","description":"Root endpoint with service information.","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/health":{"get":{"summary":"Health","description":"Health check endpoint - returns degraded if orchestrator is down.","operationId":"health_health_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/ready":{"get":{"summary":"Ready","description":"Readiness check endpoint - server is ready to accept requests.","operationId":"ready_ready_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/services":{"post":{"summary":"Create and start a new service","description":"**[Proxy]** Create and start a new service.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, parameters, and examples, see the orchestrator API documentation at:\n**POST /api/services/start** on the orchestrator service.","operationId":"create_service_api_v1_services_post","requestBody":{"required":true,"content":{"application/json":{"schema":{"allOf":[{"$ref":"#/components/schemas/ServiceRequest"}],"examples":{"simple":{"summary":"Create a basic vLLM service","value":{"recipe_name":"inference/vllm-single-node","config":{"nodes":1,"cpus":2,"memory":"8G","time":"00:30:00"}}}},"title":"Request"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ServiceResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"get":{"summary":"List Services","description":"**[Proxy]** List all services managed by the orchestrator.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, filtering options, and response schemas, see the orchestrator API documentation at:\n**GET /api/services** on the orchestrator service.","operationId":"list_services_api_v1_services_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"type":"array","items":{"$ref":"#/components/schemas/ServiceResponse"},"title":"Response List Services Api V1 Services Get"}}}}}}},"/api/v1/services/targets":{"get":{"summary":"Get Service Targets","description":"Get Prometheus scrape targets for all managed services.\n\nThis endpoint returns a list of Prometheus scrape targets for running services.\nThis allows to dynamically configure Prometheus to monitor all services managed by this server.\n\n**Returns:**\n- Content-Type: `application/json`\n- Body: JSON object compatible with Prometheus file-based service discovery format\n\n**Example Response:**\n```json\n[\n  {\n    \"targets\": [\"server:8001\"],\n    \"labels\": {\n      \"job\": \"service-3642874\",\n      \"service_id\": \"3642874\",\n      \"recipe_name\": \"inference/vllm-single-node\"\n    }\n  },\n  ...\n]\n```","operationId":"get_service_targets_api_v1_services_targets_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/services/{service_id}":{"get":{"summary":"Get Service","description":"**[Proxy]** Get detailed information about a specific service or service group.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, response formats, and service/group detection logic, see the orchestrator API documentation at:\n**GET /api/services/{service_id}** on the orchestrator service.","operationId":"get_service_api_v1_services__service_id__get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ServiceResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"summary":"Stop Service","description":"**[Proxy]** DEPRECATED - Stop a service (use POST /services/{service_id}/status instead).\n\nThis endpoint proxies to the orchestrator's service stop API.\n\n**DEPRECATION NOTICE:** Use POST /services/{service_id}/status with {\"status\": \"cancelled\"} instead.\n\nFor detailed documentation and recommended alternatives, see the orchestrator API documentation at:\n**POST /api/services/stop/{service_id}** on the orchestrator service.","operationId":"stop_service_api_v1_services__service_id__delete","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/service-groups":{"get":{"summary":"List Service Groups","description":"**[Proxy]** List all service groups.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, response format, and filtering options, see the orchestrator API documentation at:\n**GET /api/service-groups** on the orchestrator service.","operationId":"list_service_groups_api_v1_service_groups_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/service-groups/{group_id}":{"get":{"summary":"Get Service Group","description":"**[Proxy]** Get detailed information about a service group and all its replicas.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, replica information, and health status details, see the orchestrator API documentation at:\n**GET /api/service-groups/{group_id}** on the orchestrator service.","operationId":"get_service_group_api_v1_service_groups__group_id__get","parameters":[{"name":"group_id","in":"path","required":true,"schema":{"type":"string","title":"Group Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"summary":"Stop Service Group","description":"**[Proxy]** Stop all replicas in a service group.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, response format, and error handling, see the orchestrator API documentation at:\n**DELETE /api/service-groups/{group_id}** on the orchestrator service.","operationId":"stop_service_group_api_v1_service_groups__group_id__delete","parameters":[{"name":"group_id","in":"path","required":true,"schema":{"type":"string","title":"Group Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/service-groups/{group_id}/status":{"get":{"summary":"Get Service Group Status","description":"**[Proxy]** Get aggregated status of a service group.\n\nThis endpoint proxies to the orchestrator's service management API.\n\nFor detailed documentation, status values, and health metrics, see the orchestrator API documentation at:\n**GET /api/service-groups/{group_id}/status** on the orchestrator service.","operationId":"get_service_group_status_api_v1_service_groups__group_id__status_get","parameters":[{"name":"group_id","in":"path","required":true,"schema":{"type":"string","title":"Group Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"post":{"summary":"Update Service Group Status","description":"**[Proxy]** Update the status of a service group (primarily for cancelling).\n\nThis endpoint proxies to the orchestrator's service group management API.\nSimilar to single service status updates, this allows graceful cancellation\nof all replicas in a group while preserving metadata for analysis.\n\nFor detailed documentation, see the orchestrator API documentation at:\n**POST /api/service-groups/{group_id}/status** on the orchestrator service.","operationId":"update_service_group_status_api_v1_service_groups__group_id__status_post","parameters":[{"name":"group_id","in":"path","required":true,"schema":{"type":"string","title":"Group Id"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","additionalProperties":{"type":"string"},"examples":{"cancel":{"summary":"Cancel a service group","value":{"status":"cancelled"}}},"title":"Status Update"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/services/{service_id}/metrics":{"get":{"summary":"Get Service Metrics","description":"**[Proxy]** Get Prometheus-compatible metrics from any service.\n\nThis endpoint proxies to the orchestrator's unified metrics API.\n\nFor detailed documentation, supported service types, metric formats, and Prometheus integration examples, see the orchestrator API documentation at:\n**GET /api/services/{service_id}/metrics** on the orchestrator service.","operationId":"get_service_metrics_api_v1_services__service_id__metrics_get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/services/{service_id}/logs":{"get":{"summary":"Get Service Logs","description":"**[Proxy]** Get SLURM logs (stdout and stderr) from a service.\n\nThis endpoint proxies to the orchestrator's service logs API.\n\nFor detailed documentation, log format descriptions, and troubleshooting tips, see the orchestrator API documentation at:\n**GET /api/services/{service_id}/logs** on the orchestrator service.","operationId":"get_service_logs_api_v1_services__service_id__logs_get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/services/{service_id}/status":{"get":{"summary":"Get Service Status","description":"**[Proxy]** Get the current detailed status of a service.\n\nThis endpoint proxies to the orchestrator's service status API.\n\nFor detailed documentation, status values, and initialization stages, see the orchestrator API documentation at:\n**GET /api/services/{service_id}/status** on the orchestrator service.","operationId":"get_service_status_api_v1_services__service_id__status_get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"post":{"summary":"Update Service Status","description":"**[Proxy]** Update the status of a service (primarily for cancelling).\n\nThis endpoint proxies to the orchestrator's service status update API.\n\nFor detailed documentation, supported status values, state transitions, and examples, see the orchestrator API documentation at:\n**POST /api/services/{service_id}/status** (or equivalent) on the orchestrator service.","operationId":"update_service_status_api_v1_services__service_id__status_post","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","additionalProperties":{"type":"string"},"examples":{"cancel":{"summary":"Cancel a running service","value":{"status":"cancelled"}}},"title":"Status Update"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/recipes":{"get":{"summary":"List Or Get Recipe","description":"**[Proxy]** List all available recipes OR get a specific recipe.\n\nThis endpoint proxies to the orchestrator's recipe management API.\n\nFor detailed documentation, query parameters, recipe structure, and examples, see the orchestrator API documentation at:\n**GET /api/recipes** on the orchestrator service.","operationId":"list_or_get_recipe_api_v1_recipes_get","parameters":[{"name":"path","in":"query","required":false,"schema":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Path"}},{"name":"name","in":"query","required":false,"schema":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Name"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vllm/services":{"get":{"summary":"List Vllm Services","description":"**[Proxy]** List all running vLLM inference services with their endpoints.\n\nThis endpoint proxies to the orchestrator's vLLM service discovery API.\n\nFor detailed documentation, endpoint resolution, and service status meanings, see the orchestrator API documentation at:\n**GET /api/vllm** (or /api/data-plane/vllm) on the orchestrator service.","operationId":"list_vllm_services_api_v1_vllm_services_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/vllm/available-models":{"get":{"summary":"List Available Vllm Models","description":"Get information about models that can be used with vLLM.\n\nThis endpoint provides information about vLLM's supported model architectures\nand how to find compatible models from HuggingFace Hub. Unlike a hardcoded model list,\nthis returns architectural compatibility information since vLLM can load ANY model\nfrom HuggingFace Hub that uses a supported architecture.\n\n**Key Information:**\n- **Model Source**: All models are downloaded from HuggingFace Hub (https://huggingface.co/models)\n- **Compatibility**: Based on model architecture, not specific model names\n- **How to Use**: Provide any HuggingFace model ID in the `VLLM_MODEL` environment variable\n- **Format**: `organization/model-name` (e.g., `meta-llama/Llama-2-7b-chat-hf`)\n\n**Returns:**\n```json\n{\n  \"model_source\": \"HuggingFace Hub\",\n  \"supported_architectures\": {\n    \"text-generation\": [\"LlamaForCausalLM\", \"MistralForCausalLM\", ...],\n    \"vision-language\": [\"LlavaForConditionalGeneration\", ...],\n    \"embedding\": [\"BertModel\", ...]\n  },\n  \"examples\": {\n    \"GPT-2 (small, for testing)\": \"gpt2\",\n    \"Llama 2 7B Chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n    \"Qwen 2.5 0.5B Instruct\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n    ...\n  },\n  \"how_to_find_models\": [\n    \"Browse HuggingFace: https://huggingface.co/models?pipeline_tag=text-generation\",\n    \"Check model card for architecture\",\n    ...\n  ],\n  \"resource_guidelines\": {\n    \"small_models\": {\n      \"size_range\": \"< 1B parameters\",\n      \"min_gpu_memory_gb\": 4,\n      ...\n    },\n    ...\n  }\n}\n```\n\n**How to Find Compatible Models:**\n1. Browse HuggingFace: https://huggingface.co/models?pipeline_tag=text-generation\n2. Check the model's architecture in its `config.json` file\n3. Verify the architecture is in vLLM's supported list (returned by this endpoint)\n4. Use the model ID when creating a vLLM service\n\n**Example Usage:**\n\nFirst, query this endpoint to see supported architectures and examples:\n```bash\ncurl http://localhost:8001/vllm/available-models\n```\n\nThen create a service with any compatible model:\n```json\n{\n  \"recipe_name\": \"inference/vllm-single-node\",\n  \"config\": {\n    \"environment\": {\n      \"VLLM_MODEL\": \"Qwen/Qwen2.5-7B-Instruct\"\n    }\n  }\n}\n```\n\n**Resource Planning:**\nUse the `resource_guidelines` section to estimate GPU memory requirements based on model size.\nLarger models may require multiple GPUs using tensor parallelism.\n\n**Authentication:**\nSome models (e.g., Llama 2, Llama 3) require HuggingFace authentication.\nYou'll need to set up HuggingFace credentials before deploying these models.","operationId":"list_available_vllm_models_api_v1_vllm_available_models_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/vllm/search-models":{"get":{"summary":"Search Vllm Models","description":"Search HuggingFace Hub for models compatible with vLLM.\n\nThis endpoint queries the HuggingFace Hub API to find models that match your search criteria\nand checks their compatibility with vLLM's supported architectures.\n\n**Query Parameters:**\n- `query`: Search string (e.g., \"llama\", \"mistral\", \"qwen\", \"instruct\")\n- `architecture`: Filter by specific architecture class name\n- `limit`: Maximum results to return (1-100, default: 20)\n- `sort_by`: Sort order - \"downloads\", \"likes\", \"trending\", or \"created_at\"\n\n**Returns:**\n```json\n{\n  \"models\": [\n    {\n      \"id\": \"meta-llama/Llama-2-7b-chat-hf\",\n      \"downloads\": 1500000,\n      \"likes\": 5000,\n      \"architecture\": \"LlamaForCausalLM\",\n      \"vllm_compatible\": true,\n      \"created_at\": \"2023-07-18T...\",\n      \"tags\": [\"llama\", \"text-generation\", \"conversational\"]\n    },\n    ...\n  ],\n  \"total\": 20\n}\n```\n\n**Example Searches:**\n\nFind popular Llama models:\n```\nGET /vllm/search-models?query=llama&sort_by=downloads&limit=10\n```\n\nFind Qwen instruction models:\n```\nGET /vllm/search-models?query=qwen+instruct&limit=15\n```\n\nFind all models with specific architecture:\n```\nGET /vllm/search-models?architecture=MistralForCausalLM\n```\n\n**Use Case:**\nUse this to discover new models before creating a vLLM service. The `vllm_compatible`\nfield indicates whether the model uses an architecture supported by vLLM.","operationId":"search_vllm_models_api_v1_vllm_search_models_get","parameters":[{"name":"query","in":"query","required":false,"schema":{"anyOf":[{"type":"string"},{"type":"null"}],"description":"Search query (e.g., 'llama', 'mistral', 'qwen')","title":"Query"},"description":"Search query (e.g., 'llama', 'mistral', 'qwen')"},{"name":"architecture","in":"query","required":false,"schema":{"anyOf":[{"type":"string"},{"type":"null"}],"description":"Filter by architecture (e.g., 'LlamaForCausalLM')","title":"Architecture"},"description":"Filter by architecture (e.g., 'LlamaForCausalLM')"},{"name":"limit","in":"query","required":false,"schema":{"type":"integer","maximum":100,"minimum":1,"description":"Maximum number of results (1-100)","default":20,"title":"Limit"},"description":"Maximum number of results (1-100)"},{"name":"sort_by","in":"query","required":false,"schema":{"type":"string","description":"Sort by: downloads, likes, trending, created_at","default":"downloads","title":"Sort By"},"description":"Sort by: downloads, likes, trending, created_at"}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vllm/model-info/{model_id}":{"get":{"summary":"Get Model Info","description":"Get detailed information about a specific model from HuggingFace Hub.\n\nThis endpoint fetches comprehensive information about a model including its architecture,\nsize, compatibility with vLLM, and download statistics.\n\n**Path Parameters:**\n- `model_id`: HuggingFace model ID (e.g., \"meta-llama/Llama-2-7b-hf\", \"Qwen/Qwen2.5-3B-Instruct\")\n\n**Returns:**\n```json\n{\n  \"id\": \"Qwen/Qwen2.5-3B-Instruct\",\n  \"architecture\": \"Qwen2ForCausalLM\",\n  \"vllm_compatible\": true,\n  \"task_type\": \"text-generation\",\n  \"downloads\": 250000,\n  \"likes\": 1200,\n  \"tags\": [\"qwen2\", \"instruct\", \"chat\"],\n  \"size_bytes\": 6442450944,\n  \"size_gb\": 6.0,\n  \"pipeline_tag\": \"text-generation\",\n  \"library_name\": \"transformers\"\n}\n```\n\n**Fields:**\n- `vllm_compatible`: Whether this model can be loaded by vLLM\n- `task_type`: Type of task (text-generation, vision-language, embedding)\n- `size_gb`: Approximate model size in gigabytes\n- `architecture`: The model's architecture class\n\n**Example Usage:**\n\nCheck if a model is compatible before deployment:\n```bash\ncurl http://localhost:8001/vllm/model-info/Qwen/Qwen2.5-7B-Instruct\n```\n\nThen use the model ID to create a service:\n```json\n{\n  \"recipe_name\": \"inference/vllm-single-node\",\n  \"config\": {\n    \"environment\": {\n      \"VLLM_MODEL\": \"Qwen/Qwen2.5-7B-Instruct\"\n    }\n  }\n}\n```\n\n**Note:** Some models require HuggingFace authentication. Check the model page on\nHuggingFace Hub if you encounter access errors.","operationId":"get_model_info_api_v1_vllm_model_info__model_id__get","parameters":[{"name":"model_id","in":"path","required":true,"schema":{"type":"string","title":"Model Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vector-db/services":{"get":{"summary":"List Vector Db Services","description":"**[Proxy]** List all running vector database services.\n\nThis endpoint proxies to the orchestrator's vector database service discovery API.\n\nFor detailed documentation, supported vector databases, and endpoint formats, see the orchestrator API documentation at:\n**GET /api/vector-db** (or /api/data-plane/vector-db) on the orchestrator service.","operationId":"list_vector_db_services_api_v1_vector_db_services_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/vector-db/{service_id}/collections":{"get":{"summary":"Get Collections","description":"**[Proxy]** Get list of collections from a vector database service.\n\nThis endpoint proxies to the orchestrator's vector database collections API.\n\nFor detailed documentation, supported operations, and response formats, see the orchestrator API documentation at:\n**GET /api/vector-db/{service_id}/collections** on the orchestrator service.","operationId":"get_collections_api_v1_vector_db__service_id__collections_get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vector-db/{service_id}/collections/{collection_name}":{"get":{"summary":"Get Collection Info","description":"**[Proxy]** Get detailed information about a specific collection.\n\nThis endpoint proxies to the orchestrator's collection info API.\n\nFor detailed documentation, collection metadata formats, and vector configuration details, see the orchestrator API documentation at:\n**GET /api/vector-db/{service_id}/collections/{collection_name}** on the orchestrator service.","operationId":"get_collection_info_api_v1_vector_db__service_id__collections__collection_name__get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}},{"name":"collection_name","in":"path","required":true,"schema":{"type":"string","title":"Collection Name"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"put":{"summary":"Create Collection","description":"**[Proxy]** Create a new collection in the vector database.\n\nThis endpoint proxies to the orchestrator's collection creation API.\n\nFor detailed documentation, vector size configuration, distance metrics, and examples, see the orchestrator API documentation at:\n**PUT /api/vector-db/{service_id}/collections/{collection_name}** on the orchestrator service.","operationId":"create_collection_api_v1_vector_db__service_id__collections__collection_name__put","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}},{"name":"collection_name","in":"path","required":true,"schema":{"type":"string","title":"Collection Name"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","examples":{"basic":{"summary":"Create a basic collection","value":{"vector_size":384,"distance":"Cosine"}},"euclidean":{"summary":"Create collection with Euclidean distance","value":{"vector_size":768,"distance":"Euclid"}}},"title":"Request"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"summary":"Delete Collection","description":"**[Proxy]** Delete a collection from the vector database.\n\nThis endpoint proxies to the orchestrator's collection deletion API.\n\nFor detailed documentation, operation details, and error handling, see the orchestrator API documentation at:\n**DELETE /api/vector-db/{service_id}/collections/{collection_name}** on the orchestrator service.","operationId":"delete_collection_api_v1_vector_db__service_id__collections__collection_name__delete","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}},{"name":"collection_name","in":"path","required":true,"schema":{"type":"string","title":"Collection Name"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vector-db/{service_id}/collections/{collection_name}/points":{"put":{"summary":"Upsert Points","description":"**[Proxy]** Insert or update points (vectors with payloads) in a collection.\n\nThis endpoint proxies to the orchestrator's vector upsert API.\n\nFor detailed documentation, point formats, payload structures, and batch operations, see the orchestrator API documentation at:\n**PUT /api/vector-db/{service_id}/collections/{collection_name}/points** on the orchestrator service.","operationId":"upsert_points_api_v1_vector_db__service_id__collections__collection_name__points_put","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}},{"name":"collection_name","in":"path","required":true,"schema":{"type":"string","title":"Collection Name"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","examples":{"simple":{"summary":"Insert a single point","value":{"points":[{"id":1,"vector":[0.1,0.2,0.3,0.4],"payload":{"text":"Example document"}}]}},"multiple":{"summary":"Insert multiple points","value":{"points":[{"id":1,"vector":[0.1,0.2,0.3],"payload":{"text":"First doc"}},{"id":2,"vector":[0.4,0.5,0.6],"payload":{"text":"Second doc"}}]}}},"title":"Request"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vector-db/{service_id}/collections/{collection_name}/points/search":{"post":{"summary":"Search Points","description":"**[Proxy]** Search for similar vectors in a collection.\n\nThis endpoint proxies to the orchestrator's vector search API.\n\nFor detailed documentation, query parameters, scoring methods, and filtering options, see the orchestrator API documentation at:\n**POST /api/vector-db/{service_id}/collections/{collection_name}/points/search** on the orchestrator service.","operationId":"search_points_api_v1_vector_db__service_id__collections__collection_name__points_search_post","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}},{"name":"collection_name","in":"path","required":true,"schema":{"type":"string","title":"Collection Name"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","examples":{"basic":{"summary":"Basic similarity search","value":{"query_vector":[0.1,0.2,0.3,0.4],"limit":5}}},"title":"Request"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/orchestrator/endpoint":{"get":{"summary":"Get Orchestrator Endpoint","description":"Get the internal endpoint of the orchestrator service.\n\nThis endpoint returns the internal URL of the orchestrator running on the compute node.\nClients can use this to communicate directly with the orchestrator if needed.\n\n**Returns:**\n```json\n{\n  \"endpoint\": \"http://mel1234:8003\"\n}\n```","operationId":"get_orchestrator_endpoint_api_v1_orchestrator_endpoint_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/api/v1/vllm/{service_id}/prompt":{"post":{"summary":"Send a prompt to a running vLLM service","description":"**[Proxy]** Send a text prompt to a running vLLM inference service.\n\nThis endpoint proxies to the orchestrator's vLLM prompt API.\n\nFor detailed documentation, request parameters, response formats, and examples, see the orchestrator API documentation at:\n**POST /api/vllm/{service_id}/prompt** (or /api/data-plane/vllm/{service_id}/prompt) on the orchestrator service.","operationId":"prompt_vllm_service_api_v1_vllm__service_id__prompt_post","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","examples":{"simple":{"summary":"Basic prompt","value":{"prompt":"Write a short haiku about AI."}},"with_model":{"summary":"Prompt specifying model","value":{"prompt":"Hello","model":"gpt2","max_tokens":64}}},"title":"Request"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/vllm/{service_id}/models":{"get":{"summary":"Get Vllm Models","description":"**[Proxy]** Get the list of models served by a running vLLM service.\n\nThis endpoint proxies to the orchestrator's vLLM model discovery API.\n\nFor detailed documentation, model formats, and service status handling, see the orchestrator API documentation at:\n**GET /api/vllm/{service_id}/models** (or /api/data-plane/vllm/{service_id}/models) on the orchestrator service.","operationId":"get_vllm_models_api_v1_vllm__service_id__models_get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/v1/metrics/{service_id}":{"get":{"summary":"Get Service Metrics Generic","description":"Get Prometheus metrics from any service (generic endpoint).\n\nThis is a unified metrics endpoint that automatically routes to the appropriate\nservice-specific metrics endpoint based on the service's recipe type.\n\n**Path Parameters:**\n- `service_id`: The SLURM job ID or service group ID of the service\n\n**Returns (Success):**\n- Content-Type: `text/plain; version=0.0.4`\n- Body: Prometheus text format metrics\n\n**Returns (Error):**\n- Content-Type: `application/json`\n- Body: JSON error object with details\n\n**Examples:**\n```bash\n# Get metrics from any service\ncurl http://localhost:8001/api/v1/metrics/3642874\n```\n\n**Integration with Prometheus:**\n```yaml\nscrape_configs:\n  - job_name: 'managed-services'\n    static_configs:\n      - targets: ['server:8001']\n    metrics_path: '/api/v1/metrics/<service_id>'\n    scrape_interval: 15s\n```\n\n**Note:** This endpoint determines the service type automatically and routes\nto the appropriate metrics fetcher (vLLM, Qdrant, etc.).","operationId":"get_service_metrics_generic_api_v1_metrics__service_id__get","parameters":[{"name":"service_id","in":"path","required":true,"schema":{"type":"string","title":"Service Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/orchestrator/services":{"get":{"summary":"Get Orchestrator Services","description":"Get services from orchestrator","operationId":"get_orchestrator_services_orchestrator_services_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/orchestrator/metrics":{"get":{"summary":"Get Orchestrator Metrics","description":"Get metrics from orchestrator","operationId":"get_orchestrator_metrics_orchestrator_metrics_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/orchestrator/configure":{"post":{"summary":"Configure Orchestrator","description":"Configure orchestrator load balancing","operationId":"configure_orchestrator_orchestrator_configure_post","parameters":[{"name":"strategy","in":"query","required":true,"schema":{"type":"string","title":"Strategy"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}}},"components":{"schemas":{"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ServiceRequest":{"properties":{"recipe_name":{"type":"string","title":"Recipe Name"},"config":{"type":"object","title":"Config","default":{}}},"type":"object","required":["recipe_name"],"title":"ServiceRequest","description":"Schema for service creation requests."},"ServiceResponse":{"properties":{"id":{"type":"string","title":"Id"},"name":{"type":"string","title":"Name"},"recipe_name":{"type":"string","title":"Recipe Name"},"status":{"type":"string","title":"Status"},"config":{"type":"object","title":"Config"},"created_at":{"type":"string","title":"Created At"},"type":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Type"},"replicas":{"anyOf":[{"items":{"type":"object"},"type":"array"},{"type":"null"}],"title":"Replicas"},"num_replicas":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Num Replicas"},"num_nodes":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Num Nodes"},"replicas_per_node":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Replicas Per Node"},"total_replicas":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Total Replicas"},"node_jobs":{"anyOf":[{"items":{"type":"object"},"type":"array"},{"type":"null"}],"title":"Node Jobs"},"group_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Group Id"},"replica_index":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Replica Index"}},"type":"object","required":["id","name","recipe_name","status","config","created_at"],"title":"ServiceResponse","description":"Schema for service responses.\n\nFor regular services, this contains basic service information.\nFor service groups (replicas), includes additional fields for group management."},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"}}}}