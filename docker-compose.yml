services:
  server:
    build:
      context: ./services/server
      dockerfile: Dockerfile
    container_name: benchmarking-ai-server
    ports:
      - "8001:8001"
    volumes:
      # Mount source code for hot-reload during development
      - ./services/server/src:/app/src
      - ./services/server/tests:/app/tests
      - ./services/server/pytest.ini:/app/pytest.ini
      - ./services/server/logs:/app/logs
      # Mount server endpoint file so client can find it
      - ./services/server/.server-endpoint:/app/.server-endpoint
      # Mount SSH agent socket for secure authentication (no raw keys exposed)
      - ${SSH_AUTH_SOCK}:/tmp/ssh-agent.sock:ro
    environment:
      # SSH Configuration for MeluXina
      - SSH_HOST=${SSH_HOST}
      - SSH_PORT=${SSH_PORT}
      - SSH_USER=${SSH_USER}
      - SSH_KEY_PATH=${SSH_KEY_PATH}
      - REMOTE_BASE_PATH=${REMOTE_BASE_PATH}
      - SSH_AUTH_SOCK=/tmp/ssh-agent.sock
      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    # Load additional service-specific variables
    env_file:
      - .env
    networks: 
      - ai-factory
    stdin_open: true
    tty: true
    restart: unless-stopped

  # Prometheus - Metrics storage and scraping
  prometheus:
    build:
      context: ./services/prometheus
      dockerfile: Dockerfile
    container_name: benchmarking-ai-prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus-storage:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-admin-api'        # Enable admin operations
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - ai-factory
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      server:
        condition: service_started

  monitoring:
    build:
      context: ./services/monitoring
      dockerfile: Dockerfile
    container_name: benchmarking-ai-monitoring
    ports:
      - "8002:8002"
    volumes:
      # Mount source code for hot-reload during development
      - ./services/monitoring/src:/app/src
      - ./services/monitoring/tests:/app/tests
      - ./services/monitoring/logs:/app/logs
    environment:
      # Prometheus settings
      - MONITORING_PROMETHEUS_URL=http://prometheus:9090
      
      # Server API (for metrics proxy)
      - MONITORING_SERVER_API_URL=http://server:8001
      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - APP_LOG_DIR=/app/logs
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
    networks: 
      - ai-factory
    stdin_open: true
    tty: true
    restart: unless-stopped
    depends_on:
      prometheus:
        condition: service_healthy
      server:
        condition: service_started

  # TODO: Add other services when ready
  # client:
  #   build:
  #     context: ./services/client
  #     dockerfile: Dockerfile
  #   container_name: benchmarking-ai-client
  #   ...

  # Logs

  # Front-end
  grafana:
    build:
      context: ./services/grafana
      dockerfile: Dockerfile
    container_name: benchmarking-ai-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    restart: unless-stopped
    networks:
      - ai-factory
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_started
      grafana-renderer:
        condition: service_started

  grafana-renderer:
    image: grafana/grafana-image-renderer:3.10.0
    container_name: benchmark-ai-grafana-renderer
    ports:
      - "8081:8081"
    restart: unless-stopped
    networks:
      - ai-factory

  loki:
    build:
      context: ./services/loki
      dockerfile: Dockerfile
    container_name: benchmarking-ai-loki
    ports:
      - "3100:3100"
    volumes:
      - loki-storage:/loki
    networks:
      - ai-factory
    restart: unless-stopped

  alloy:
    build:
      context: ./services/alloy
      dockerfile: Dockerfile
    ports:
      - 12345:12345
      - 4318:4318
    volumes:
      - ./services/server/logs:/logs
    networks:
      - ai-factory
    restart: unless-stopped
    depends_on:
      - loki

  # Documentation service
  docs:
    build:
      context: ./docs-src
      dockerfile: Dockerfile
    container_name: benchmarking-ai-docs
    ports:
      - "8000:8000"
    volumes:
      # Mount docs source for hot-reload during development
      - ./docs-src:/docs-src
      - ./mkdocs.yml:/mkdocs.yml
      # Mount output directory
      - ./docs:/docs
    working_dir: /
    command: mkdocs serve --dev-addr=0.0.0.0:8000
    restart: unless-stopped

networks:
  ai-factory:

volumes:
  prometheus-storage:
    driver: local
    name: prometheus-storage
  loki-storage:
    driver: local
    name: loki-storage
