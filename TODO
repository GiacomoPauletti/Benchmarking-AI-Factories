Server:
    MAIN:

    Optional:
    - Create fastembed functionality in qdrant. Use it for RAGs using HF datasets.
    - Create proper CI pipeline with actions: 
        - build: docker image with python code, etc.. is built. 
        - test: docker image is passed into test environment. Runs and must pass specific tests.


    Things to Benchmark:
    vllm:
    - tokens/sec
    - uptime seconds
    - process memory usage 
    - number of models currently loaded
    - names of models currently loaded

    vector-db: 
    - example datasets from huggingface
    - queries per second 
    - latency per vector search
    - time to build or update index
    - number of loaded collections 
    - recall ()


Client:
    MAIN:
    - Add possibility of using big prompt datasets and RAGs using the vec-db service.



Logs: 


Grafana:
- Make orchestrator launch/stop possible directly from grafana in a dedicated panel. Grey out buttons when orchestrator is down.
- Add GPU metrics.
- HFauth.
Minor:
- If I create 2 services, one does not appear in the benchmark dropdown.

Overall:
- Make everything production-ready (release tag), update docs, host them on github (make it public). 