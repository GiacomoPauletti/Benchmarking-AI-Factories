Server:
    MAIN:

    Optional:
    - Create fastembed functionality in qdrant. Use it for RAGs using HF datasets.
    - Create proper CI pipeline with actions: 
        - build: docker image with python code, etc.. is built. 
        - test: docker image is passed into test environment. Runs and must pass specific tests.


    Things to Benchmark:
    vllm:
    - tokens/sec
    - uptime seconds
    - process memory usage 
    - number of models currently loaded
    - names of models currently loaded

    vector-db: 
    - example datasets from huggingface
    - queries per second 
    - latency per vector search
    - time to build or update index
    - number of loaded collections 
    - recall ()


Client:
    MAIN:
    - Add possibility of using big prompt datasets and RAGs using the vec-db service.



Logs: 


Grafana:
- I would like that the "Start service" Add model choice possibility to vllm recipe service panel. And time limit
- Make all replicas (from all nodes) selectable in the services tab. Make it clearer in general
 in the dashboard start service that we are launching replicas. Maybe let the user just specify 
 the number of replicas and we map them to nodes automatically.
- Add benchmark lifecycle to temporal chart and a dedicate tab where metrics are shown.
- Make orchestrator launch/stop possible directly from grafana in a dedicated panel. Grey out buttons when orchestrator is down.
- HFauth.

Overall:
- Make everything production-ready (release tag), update docs, host them on github (make it public). 