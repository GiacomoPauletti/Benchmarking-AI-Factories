Server:
    MAIN:

    Optional:
    - Create fastembed functionality in qdrant. Use it for RAGs using HF datasets.
    - Create proper CI pipeline with actions: 
        - build: docker image with python code, etc.. is built. 
        - test: docker image is passed into test environment. Runs and must pass specific tests.


    Things to Benchmark:
    vllm:
    - tokens/sec
    - uptime seconds
    - process memory usage 
    - number of models currently loaded
    - names of models currently loaded

    vector-db: 
    - example datasets from huggingface
    - queries per second 
    - latency per vector search
    - time to build or update index
    - number of loaded collections 
    - recall ()


Client:
    MAIN:
    - Add possibility of using big prompt datasets and RAGs using the vec-db service.



Logs: 


Grafana:
- HFauth.
- I would like to make the orchestrator launch/stop possible directly from grafana in a dedicated panel in the home dashboard, preferably on the top. I would like to visibly disable any other panels/controls while orchestrator is down.
    Launching the orchestrator should be done by specifying a time limit. The session should have a counter.

Minor:
- If I create 2 services, one does not appear in the benchmark dropdown.

Overall:
- Make everything production-ready (release tag), update docs, host them on github (make it public). 
- As soon as the code is production-ready, 
    create a youtube video showcasing the project and its functionalities.
    Then update the docs and create the report.
- If there is time and energy, create qdrant functionalities for fastembed and RAGs using HF datasets.
