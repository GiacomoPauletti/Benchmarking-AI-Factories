Server:
    MAIN:

    Optional:
    - Create fastembed functionality in qdrant. Use it for RAGs using HF datasets.
    - Create proper CI pipeline with actions: 
        - build: docker image with python code, etc.. is built. 
        - test: docker image is passed into test environment. Runs and must pass specific tests.


    Things to Benchmark:
    vllm:
    - tokens/sec
    - uptime seconds
    - process memory usage 
    - number of models currently loaded
    - names of models currently loaded

    vector-db: 
    - example datasets from huggingface
    - queries per second 
    - latency per vector search
    - time to build or update index
    - number of loaded collections 
    - recall ()


Client:
    MAIN:
    - Add possibility of using big prompt datasets and RAGs using the vec-db service.



Logs: 


Grafana:
- I would like that the "Start service" Add model choice possibility to vllm recipe service panel. And time limit
- Make all replicas (from all nodes) selectable in the services tab. Make it clearer in general
 in the dashboard start service that we are launching replicas.
- Fix recipes panel to show more meaningful properties. 
- See vllm docs and improve metrics shown. 
- Add benchmark lifecycle to temporal chart and a dedicate tab where metrics are shown.
