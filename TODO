Server:
    MAIN:

    Optional:
    - Create fastembed functionality in qdrant. Use it for RAGs using HF datasets.
    - Create proper CI pipeline with actions: 
        - build: docker image with python code, etc.. is built. 
        - test: docker image is passed into test environment. Runs and must pass specific tests.


    Things to Benchmark:
    vllm:
    - tokens/sec
    - uptime seconds
    - process memory usage 
    - number of models currently loaded
    - names of models currently loaded

    vector-db: 
    - example datasets from huggingface
    - queries per second 
    - latency per vector search
    - time to build or update index
    - number of loaded collections 
    - recall ()


Client:
    MAIN:
    - Add possibility of using big prompt datasets and RAGs using the vec-db service.



Logs: 


Grafana:
- "Service" should appear like "Benchmark" in the Service and Benchmark panel.
- I don't want any status to appear after "running" in the Service and Benchmark panel. Not even bars.
- Make orchestrator launch/stop possible directly from grafana in a dedicated panel. Grey out buttons when orchestrator is down.
- Let the user just specify the number of replicas and we map them to nodes automatically.
- Make controls stricter - single node vllm fixes nodes to 1, etc..
- Add GPU metrics.
- HFauth.

Overall:
- Make everything production-ready (release tag), update docs, host them on github (make it public). 